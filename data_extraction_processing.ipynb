{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:24:17.468583Z",
     "start_time": "2020-03-04T10:24:15.239046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from tensorly.decomposition import partial_tucker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import detrend\n",
    "import numpy as np\n",
    "from ecgdetectors import Detectors\n",
    "from tqdm import tqdm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:29:24.313583Z",
     "start_time": "2020-03-04T10:29:24.308221Z"
    }
   },
   "outputs": [],
   "source": [
    "class_dict = {'Myocardial infarction':'MI', \n",
    "             'Healthy control':'CON', \n",
    "             'Cardiomyopathy':'C/HF', \n",
    "             'Bundle branch block':'BBB', \n",
    "             'Dysrhythmia':'D',\n",
    "             'Hypertrophy':'MHY',\n",
    "             'Valvular heart disease':'VHD',\n",
    "             'Myocarditis':'MYC',\n",
    "             'Heart failure (NYHA 3)':'C/HF',\n",
    "             'Heart failure (NYHA 2)':'C/HF',\n",
    "             'Heart failure (NYHA 4)':'C/HF'}\n",
    "\n",
    "MICON_dict = {'Myocardial infarction':'MI', \n",
    "             'Healthy control':'CON'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:24:25.550133Z",
     "start_time": "2020-03-04T10:24:25.541290Z"
    }
   },
   "outputs": [],
   "source": [
    "def patient_classes(folder):\n",
    "    '''Creates a unique list of patients with their respective classes, droping unlabeled data.\n",
    "        folder: the folder path containing the data eg ptb-diagnostic-ecg-database-1.0.0/'''\n",
    "    patient_class = []\n",
    "    with open(folder+'RECORDS') as f:\n",
    "        file_names = [x.strip() for x in f]\n",
    "    for x in file_names:\n",
    "        patient = x.split('/')[0]\n",
    "        with open(folder+x+'.hea') as f:\n",
    "            for line in f:\n",
    "                if 'Reason for admission:' in line:\n",
    "                    try:\n",
    "                        patient_class.append((patient, class_dict[line.split(':')[-1].strip()]))\n",
    "                    except:\n",
    "                        pass\n",
    "    return [*{*patient_class}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T09:21:58.241026Z",
     "start_time": "2020-03-12T09:21:58.233570Z"
    }
   },
   "outputs": [],
   "source": [
    "def patient_tt_split(zip_list, train, test, classes=None):\n",
    "    '''Splits the patients into a train and test set before processing to prevent patient level data leakage to the test set.\n",
    "        zip_list: a list of (patient_id, class) tuples\n",
    "        train: training proportion\n",
    "        test: testing proportion\n",
    "        classes: optional (default: None) A list of classes to include in the data sets, None includes all classes'''\n",
    "    if classes == None:\n",
    "        X, y = zip(*zip_list)\n",
    "        return train_test_split(X, y, train_size=train, test_size=test, stratify=y, random_state=1)\n",
    "    else:\n",
    "        X, y = zip(*[x for x in zip_list if x[1] in classes])\n",
    "        return train_test_split(X, y, train_size=train, test_size=test, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:24:34.489535Z",
     "start_time": "2020-03-04T10:24:34.480274Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_load_ptb(folder, patient_set):\n",
    "    '''Extracts the data from the files, processes it and returns an array and target list.\n",
    "        folder: data folder path\n",
    "        patient set: a list of patient file names to process'''\n",
    "    full_data = []\n",
    "    target = []\n",
    "    global error_list\n",
    "    error_list = []\n",
    "    with open(folder+'RECORDS') as f:\n",
    "        file_names = [x.strip() for x in f]\n",
    "    for file in tqdm(file_names):\n",
    "        for patient in patient_set:\n",
    "            if patient in file:\n",
    "                raw = wfdb.rdsamp(folder+file)\n",
    "                class_label = raw[1]['comments'][4].split(': ')[-1]\n",
    "                try:\n",
    "                    target.append(MICON_dict[class_label])\n",
    "                    full_data.append(wave_processing_pad(raw[0]))\n",
    "                except:\n",
    "                    pass\n",
    "    return np.array(full_data), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:24:35.862582Z",
     "start_time": "2020-03-04T10:24:35.847582Z"
    }
   },
   "outputs": [],
   "source": [
    "def wave_processing_pad(data):\n",
    "    '''R peaks are detected and compared between channels 0 and 1 for redundancy. Signals with peaks taller half the R peak height in the ST segment are discarded.\n",
    "    Beats are sliced by R index and placed in an array padded with zeros to 200 beats as some recordings contain less beats.'''\n",
    "    red_channel_data = data[:,0:12]\n",
    "    \n",
    "    detector = Detectors(1000)\n",
    "    swt_1_peaks = detector.swt_detector(detrend(red_channel_data[:,1]))[1:-1]\n",
    "    swt_0_peaks = detector.swt_detector(detrend(red_channel_data[:,0]))[1:-1]\n",
    "    \n",
    "    if len(swt_1_peaks) > len(swt_0_peaks):\n",
    "        small_list = swt_0_peaks\n",
    "        long_list = swt_1_peaks\n",
    "    else:\n",
    "        small_list = swt_1_peaks\n",
    "        long_list = swt_0_peaks\n",
    "    \n",
    "    diff = [swt_0_peaks[i]-swt_1_peaks[i] for i in range(len(small_list))]\n",
    "\n",
    "    def filt_sig_proc():\n",
    "        try:\n",
    "            for x in range(n_channels):\n",
    "                if x == 0:\n",
    "                    sig = detrend(red_channel_data[slice(y-250, y+350),x])\n",
    "                    if max(sig)/2 < max(sig[300:420]):\n",
    "                        break\n",
    "                    else:\n",
    "                        ecg_vec[i,:,x] = sig\n",
    "                else:\n",
    "                    ecg_vec[i,:,x] = detrend(red_channel_data[slice(y-250, y+350),x])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    \n",
    "    n_beats = 200\n",
    "    n_channels = 12\n",
    "    n_samples = 600\n",
    "    ecg_vec = np.zeros((n_beats, n_samples, n_channels))\n",
    "    for i,y in enumerate(small_list):\n",
    "        if abs(diff[i]) > 20:\n",
    "            for z in long_list:\n",
    "                if abs(y-z) > 50:\n",
    "                    pass\n",
    "                else:\n",
    "                    filt_sig_proc()\n",
    "        else:\n",
    "            filt_sig_proc()\n",
    "    return ecg_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:24:36.603875Z",
     "start_time": "2020-03-04T10:24:36.599909Z"
    }
   },
   "outputs": [],
   "source": [
    "def stack_and_tensor(data):\n",
    "    return tensorly.base.vec_to_tensor(np.stack(data), (len(data), *data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:24:36.814588Z",
     "start_time": "2020-03-04T10:24:36.809599Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_tensor(X, y, train_size, test_size, random_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    return stack_and_tensor(X_train), stack_and_tensor(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:24:37.344582Z",
     "start_time": "2020-03-04T10:24:37.340228Z"
    }
   },
   "outputs": [],
   "source": [
    "def decomposition_fit(tensor, n_channels):\n",
    "    return partial_tucker(tensor, (0,1,3), ranks=(1, 1, 600, n_channels), init='random', n_iter_max=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:24:37.905829Z",
     "start_time": "2020-03-04T10:24:37.896681Z"
    }
   },
   "outputs": [],
   "source": [
    "def reshapeing(X, y, channels):\n",
    "    '''Reshapes data removing the recording axis and any padding beats, as well as some channels if dimensionality reduction has been applied.\n",
    "    X: data (array)\n",
    "    y: data labels (list or array)\n",
    "    channels: number of channels (int)'''\n",
    "    mask = np.zeros((X.shape[0], X.shape[1]))\n",
    "    new_y = []\n",
    "    for record in range(X.shape[0]):\n",
    "        for beat in range(X.shape[1]):\n",
    "            if np.any(X[record,beat,:,:]):\n",
    "                mask[record,beat] = 1\n",
    "                new_y.append(y[record])\n",
    "    \n",
    "    print(len(new_y))\n",
    "    print(mask.sum())\n",
    "    new_X = np.zeros((len(new_y), X.shape[2], channels))\n",
    "\n",
    "    count = 0\n",
    "    for record in range(X.shape[0]):\n",
    "        for beat in range(X.shape[1]):\n",
    "            if mask[record,beat]:\n",
    "                new_X[count,:,:channels] = X[record,beat,:,:channels]\n",
    "                count += 1\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MICON Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:29:32.505284Z",
     "start_time": "2020-03-04T10:29:32.302198Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patient_zip = patient_classes('/Users/foleyc/ga/DSI11-lessons/projects/project-capstone/resources/ptb-diagnostic-ecg-database-1.0.0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:29:38.336060Z",
     "start_time": "2020-03-04T10:29:38.312502Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_patients, test_patients, ytr , ytest = patient_tt_split(patient_zip, 0.7, 0.3, classes=['MI', 'CON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:35:48.223891Z",
     "start_time": "2020-03-04T10:32:23.738337Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:15<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = data_load_ptb('/Users/foleyc/ga/DSI11-lessons/projects/project-capstone/resources/ptb-diagnostic-ecg-database-1.0.0/', 'RECORDS', train_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 549/549 [02:08<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = data_load_ptb('C://Users/Calum/project_work/ptb-diagnostic-ecg-database-1.0.0/', 'RECORDS', test_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T15:24:36.125083Z",
     "start_time": "2020-03-04T15:24:33.024252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37077\n",
      "37077.0\n"
     ]
    }
   ],
   "source": [
    "X_train_full, y_train_full = reshapeing(X_train, y_train, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17583\n",
      "17583.0\n"
     ]
    }
   ],
   "source": [
    "X_test_full, y_test_full = reshapeing(X_test, y_test, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['full/y_test']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_train_full, 'full/X_train')\n",
    "\n",
    "joblib.dump(X_test_full, 'full/X_test')\n",
    "\n",
    "joblib.dump(y_train_full, 'full/y_train')\n",
    "\n",
    "joblib.dump(y_test_full, 'full/y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T15:23:50.084006Z",
     "start_time": "2020-03-04T15:22:51.488560Z"
    }
   },
   "outputs": [],
   "source": [
    "decomp = decomposition_fit(X_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T15:25:17.097465Z",
     "start_time": "2020-03-04T15:25:12.722718Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(X_train.shape[0]):\n",
    "    for j in range(X_train.shape[1]):\n",
    "        X_train[i,j,:,:] = np.dot(X_train[i,j,:,:], decomp[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    for j in range(X_test.shape[1]):\n",
    "        X_test[i,j,:,:] = np.dot(X_test[i,j,:,:], decomp[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T15:25:28.216598Z",
     "start_time": "2020-03-04T15:25:24.862782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37077\n",
      "37077.0\n"
     ]
    }
   ],
   "source": [
    "X_train_red, y_train_red = reshapeing(X_train, y_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17583\n",
      "17583.0\n"
     ]
    }
   ],
   "source": [
    "X_test_red, y_test_red = reshapeing(X_test, y_test, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T15:26:35.281111Z",
     "start_time": "2020-03-04T15:26:35.267171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37077, 600, 6), (37077, 600, 12))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_red.shape, X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reduced/y_test']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_train_red, 'reduced/X_train')\n",
    "\n",
    "joblib.dump(X_test_red, 'reduced/X_test')\n",
    "\n",
    "joblib.dump(y_train_red, 'reduced/y_train')\n",
    "\n",
    "joblib.dump(y_test_red, 'reduced/y_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "282px",
    "left": "819px",
    "right": "20px",
    "top": "117px",
    "width": "392px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
